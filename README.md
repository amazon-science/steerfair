# Discovering Bias in Latent Space: An Unsupervised Debiasing Approach

<h5 align="center"><i>"Debias your LLMs without any label supervision."</i></h5>

> [**Discovering Bias in Latent Space: An Unsupervised Debiasing Approach**]([https://arxiv.org/abs/2304.04704](https://arxiv.org/html/2406.03631v1))<br>
> [Dyah Adila ](https://dyahadila.github.io/), [Shuai Zhang](https://cheungdaven.github.io/), [Boran Han](https://boranhan.github.io/), [Bernie Wang](http://web.mit.edu/~ywang02/www/)






## Main Contributions

1) We propose SteerFair, an unsupervised inference-time activation steering algorithm to mitigate foundation model bias.
2) We demonstrate that SteerFair can effectively address the instability concerning option ordering in question-answering tasks. Furthermore, our findings demonstrate that the bias direction pinpointed by SteerFair is generalizable across datasets with the same task.
3) Extensive experimental evidence shows improvement on three instruction-tuned models, with reduced performance variability by 10.86\% accuracy points across three datasets.

## Installation 
## Data preparation

## Pre-trained Models

## Training and Evaluation

## Contact
If you have any questions, please feel free to create an issue on this repository.

## Citation
If you find this repo useful, please star (â˜…) this repository or cite the following bibtex entry:

```
@article{adila2024discovering,
  title={Discovering Bias in Latent Space: An Unsupervised Debiasing Approach},
  author={Adila, Dyah and Zhang, Shuai and Han, Boran and Wang, Yuyang},
  journal={ICML},
  year={2024}
}

```

## Acknowledgements

Our code is based on [LLaVA](https://github.com/haotian-liu/LLaVA) repositories. We thank the authors for releasing their code. 
